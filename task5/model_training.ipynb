{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all attributes and class\n",
    "attr_list = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class_values\"]\n",
    "to_train = [\"maint\", \"doors\", \"lug_boot\", \"safety\", \"class_values\"]\n",
    "attr_index = {\n",
    "    \"buying\": {0:\"vhigh\", 1:\"high\", 2:\"med\", 3:\"low\"},\n",
    "    \"maint\": {0:\"vhigh\", 1:\"high\", 2:\"med\", 3:\"low\"},\n",
    "    \"doors\": {0:\"2\", 1:\"3\", 2:\"4\", 3:\"5more\"},\n",
    "    \"persons\": {0:\"2\", 1:\"4\", 2:\"more\"},\n",
    "    \"lug_boot\": {0:\"small\", 1:\"med\", 2:\"big\"},\n",
    "    \"safety\": {0:\"low\", 1:\"med\", 2:\"high\"},\n",
    "    \"class_values\": {0:\"unacc\", 1:\"acc\", 2:\"good\", 3:\"vgood\"}\n",
    "}\n",
    "\n",
    "#  index list\n",
    "reverse_index = {k:{attr_index[k][index]: index for index in attr_index[k]} for k in attr_list}\n",
    "\n",
    "def convert_to_index(row):\n",
    "    retval = []\n",
    "    for i, attr in enumerate(row):\n",
    "        retval.append((reverse_index[attr_list[i]][attr]+1)/4)\n",
    "    return retval\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('.', 'data', 'car.data')\n",
    "df_data = []\n",
    "# load data\n",
    "with open(data_path, \"r\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in csvreader:\n",
    "        df_data.append(convert_to_index(row))\n",
    "        \n",
    "df = pd.DataFrame(df_data, columns=attr_list)\n",
    "df = df.drop(['persons'], axis=1)\n",
    "df = df.sample(frac = 1)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['train_data'] = df[to_train].values.tolist()\n",
    "\n",
    "label_data = df['buying'].to_list()\n",
    "train_data = df['train_data'].to_list()\n",
    "           \n",
    "# len(train_data), len(label_data)\n",
    "# label_data[1000], train_data[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training set/validation set/test set\n",
    "x_train = np.asarray(train_data)\n",
    "y_train = np.asarray(label_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 25)          150025    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 25)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3328      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 153,869\n",
      "Trainable params: 153,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.keras.backend.clear_session()\n",
    "max_features = 6000\n",
    "embedding_dim = 25\n",
    "#create model\n",
    "model = tf.keras.Sequential([\n",
    "  keras.layers.Embedding(max_features + 1, embedding_dim),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.GlobalAveragePooling1D(),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dense(4, activation='sigmoid')])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3558 - accuracy: 5.7870e-04\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3180 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2755 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2253 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1686 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1047 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0341 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9588 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8827 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8134 - accuracy: 0.0000e+00\n",
      "Wall time: 416 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "fitModel = model.fit(x=x_train, y=y_train, epochs=10, batch_size=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 - 0s - loss: 0.7680 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_train,  y_train, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32433265 0.25857854 0.20868695 0.20840186] 0.5 [0.75, 0.5, 0.25, 0.75, 0.25]\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict([x_train[1000]])\n",
    "print(predictions[0], label_data[1000], train_data[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32433265 0.25857854 0.20868695 0.20840186]\n"
     ]
    }
   ],
   "source": [
    "def get_list(attr):\n",
    "    retval = []\n",
    "    for key in attr_list[1:]:\n",
    "        if key in attr:\n",
    "            retval.append((reverse_index[key][attr[key]]+1)/4)\n",
    "        else:\n",
    "            retval.append(0)\n",
    "    return retval\n",
    "        \n",
    "\n",
    "check_attr = {\n",
    "    \"maint\": \"high\",\n",
    "    \"doors\": \"4\",\n",
    "    \"lug_boot\": \"big\",\n",
    "    \"safety\": \"high\",\n",
    "    \"class_values\": \"good\"\n",
    "    }\n",
    "check_attr_index = get_list(check_attr)\n",
    "predictions = probability_model.predict([check_attr_index])\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
